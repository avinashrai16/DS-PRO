{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Simple linear regression aims to find a linear relationship to describe the correlation between an independent and possibly dependent variable.\n",
    "\n",
    "    It is part of supervised machine leaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple linear regression is a statistical method used to model the relationship between two continuous variables. It assumes that there is a linear relationship between the independent variable (X) and the dependent variable (Y). The goal is to find the best-fitting line, often referred to as the regression line, that minimizes the difference between the observed values of the dependent variable and the values predicted by the linear model.\n",
    "\n",
    "The equation for a simple linear regression model is:\n",
    "\n",
    "Y = beta_0 + beta_1X + epsilon\n",
    "\n",
    "Where:\n",
    "Y  is the dependent variable.\n",
    "X is the independent variable.\n",
    "beta_0 is the y-intercept (the value of  Y  when X is zero).\n",
    "beta_1 is the slope of the line (the change in Y for a one-unit change in X).\n",
    "epsilon is the error term, representing the difference between the observed and predicted values of Y.\n",
    "\n",
    "The goal of simple linear regression is to estimate the values of beta_0  and beta_1 that minimize the sum of squared errors (SSE), which is the sum of the squared differences between the observed and predicted values of Y. Once these parameters are estimated, the regression line can be used to make predictions about the dependent variable based on values of the independent variable.\n",
    "\n",
    "The estimation of beta_0 and beta_1 is typically done using the method of least squares, which involves finding the values of these parameters that minimize the SSE.\n",
    "\n",
    "Simple linear regression can be performed using various statistical software packages or programming languages like Python, R, or MATLAB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"slr-formula.png\" width=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem Statement 1**: Price of house based on area of house\n",
    "\n",
    "Area of home :1100 1200 1300...\n",
    "\n",
    "Price(target y): 50 60 70....\n",
    "\n",
    "what will be the price of house for area 1125 ?\n",
    "\n",
    "As the the target variable i.e. price need to predict it is supervised learning and as this is a continuous variable hence regression\n",
    "The target variable is plotted on y axis so in this case it will be Price\n",
    "\n",
    "This plot shows the direct relationship as the Area of home increases Price increases as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem Statement 2:**\n",
    "\n",
    "age of car : 10, 9, 7 ....\n",
    "\n",
    "selling price of car : 3.1, 4.1,5.2\n",
    "\n",
    "As the the target variable i.e. price need to predict it is supervised learning and as this is a continuous variable hence regression\n",
    "The target variable is plotted on y axis so in this case it will be selling price.\n",
    "\n",
    "This plot shows the inverse relationship as the age of the car increases selling price dips."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simple** : Only one independent variable driving the relationship for target variable hence simple (in case of multiple independent variable it is Multiple Linear Regression)\n",
    "\n",
    "**Linear**: trend is Linear that can be positive or negative\n",
    "\n",
    "**Regression** : Relationship b/w x (one or more variable) and y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"simple-linear-regression-plotting.jpg\" width=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"simple-linear-regression-formula1.jpg\" width=\"550\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    But how the linear regression finds out which is the best fit line?\n",
    "\n",
    "The goal of the linear regression algorithm is to get the best values for B0 and B1 to find the best fit line. The best fit line is a line that has the least error which means the error between predicted values and actual values should be minimum.\n",
    "\n",
    "Random Error(Residuals)\n",
    "In regression, the difference between the observed value of the dependent variable(yi) and the predicted value(predicted) is called the residuals.\n",
    "\n",
    "Œµi =  yi - ypredicted\n",
    "\n",
    "where ypredicted =   B0 + B1 Xi\n",
    "\n",
    "\n",
    "<img src =\"slr-plot.png\" width=\"330\">\n",
    "\n",
    "\n",
    "    What is the best fit line?\n",
    "    \n",
    "In simple terms, the best fit line is a line that fits the given scatter plot in the best way. Mathematically, the best fit line is obtained by minimizing the Residual Sum of Squares(RSS).\n",
    "\n",
    "The line with least error will be best fit line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Residual Sum of Squares(RSS) takes square because if only absolute value is taken it could make that two different data set looks same</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ordinary least squares (OLS or Sum of Squared Error ~ SSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"ordinary-least-squares.jpg\" width=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Cost Function for Linear Regression\n",
    "\n",
    "In the context of linear regression, the cost function, also known as the loss function, is a measure of how well the model's predictions match the actual values of the dependent variable. It quantifies the difference between the predicted values of the dependent variable and the actual observed values. The goal in linear regression is to minimize this cost function.\n",
    "\n",
    "\n",
    "The most commonly used cost function in linear regression is the Mean Squared Error (MSE) or the Sum of Squared Errors (SSE). The MSE is calculated as the average of the squared differences between the predicted values (obtained from the linear regression model) and the actual observed values of the dependent variable across all data points.\n",
    "\n",
    "Mathematically, the MSE can be expressed as:\n",
    "\n",
    "    *MSE=1ùëõ‚àëùëñ=1ùëõ(ùëåùëñ‚àíùëå^ùëñ)2*\n",
    "\n",
    "    Where:\n",
    "    ùëõ: is the number of data points.\n",
    "\n",
    "    ùëåùëñ: is the actual observed value of the dependent variable for the ùëñùë°‚Ñé data point.\n",
    "\n",
    "    ùëå^: is the predicted value of the dependent variable for the ùëñùë°‚Ñé data point, obtained from the linear regression model.\n",
    "\n",
    "\n",
    "Other cost functions, such as\n",
    "\n",
    "    Mean Absolute Error (MAE) \n",
    "can also be used depending on the specific requirements of the problem. However, MSE is more commonly used due to its mathematical properties and ease of optimization.\n",
    "\n",
    "The process of training a linear regression model involves adjusting the parameters (coefficients) of the model to minimize the cost function. This is typically done using\n",
    "\n",
    "    optimization algorithms such as gradient descent or normal equations.\n",
    "The parameters that minimize the cost function are the ones that define the best-fitting line for the data in terms of minimizing the squared differences between the observed and predicted values.\n",
    "\n",
    "\n",
    "**The cost function helps to work out the optimal values for B0 and B1, which provides the best fit line for the data points.**\n",
    "\n",
    "    Mean Squared Error (MSE)\n",
    "In Linear Regression, generally Mean Squared Error (MSE) cost function is used, which is the average of squared error that occurred between the ypredicted and yi.\n",
    "\n",
    "We calculate MSE using simple linear equation y=mx+b:\n",
    "\n",
    "MSE\n",
    "Using the MSE function, we‚Äôll update the values of B0 and B1 such that the MSE value settles at the minima.  These parameters can be determined using the gradient descent method such that the value for the cost function is minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"mse.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So MSE is the avg of OLS(ordinary least squares)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " As we have observed that there could be N number of lines and we need to find the best fit line based on the residual error so it will take very long to calculate the MSE or SSE for ech line fo that we need to use optimization optimization algorithms such as\n",
    " \n",
    "    python gradient descent or normal equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Boosting ??</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boosting is an ensemble technique that combines multiple weak learners sequentially, each focusing on correcting the errors of the previous ones. It works by adjusting the weights of misclassified instances, giving them more importance in subsequent iterations. The final model aggregates the predictions of all weak learners to form a strong learner. While powerful, boosting can lead to overfitting if not properly regularized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"boosting.png\" width=\"550\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <u>Boosting Techniques/Algorithms</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"boosting-techniques.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------\n",
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"bagging-vs-boosting.jpg\" width=\"650\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"bais-variance.png\" width=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging reduces variance and Boosting reduces bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Bagging (Bootstrap Aggregating)**: ***Reduces variance*** by averaging multiple models trained on different bootstrap samples of the data. This helps in stabilizing predictions and making the model more robust to overfitting, especially for high-variance models like decision trees.\n",
    "\n",
    "2. **Boosting**: ***Reduces bias*** by sequentially training models, where each model focuses on correcting the errors of the previous ones. This iterative process helps to improve the overall accuracy and performance of the model, particularly for weak learners. However, boosting can also lead to a reduction in variance if the base learners are sufficiently weak and the boosting process is properly regularized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "<img src=\"bais-variance-1.png\" width=\"450\">"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierarchical clustering is a method of cluster analysis which seeks to build a hierarchy of clusters. It is often used when the user wants to understand the relationships between clusters at various levels of granularity. Unlike K-means clustering, hierarchical clustering does not require the number of clusters to be specified in advance.\n",
    "\n",
    "**There are two main types of hierarchical clustering: agglomerative (bottom-up) and divisive (top-down).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Agglomerative (Bottom-Up) Hierarchical Clustering***\n",
    "1. Initialization:\n",
    "    * Start with each data point as its own cluster. If you have ùëõ data points, you start with ùëõ clusters.\n",
    "\n",
    "2. Merge Clusters:\n",
    "    * At each step, merge the two closest clusters. The distance between clusters can be defined in several ways (e.g., single linkage, complete linkage, average linkage, or Ward‚Äôs method).\n",
    "\n",
    "3. Repeat:\n",
    "    * Repeat the merging steps until only one cluster remains, forming a hierarchical tree (dendrogram)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"agglomerative-clustering.png\" width=\"450\" height=\"350\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Divisive (Top-Down) Hierarchical Clustering***\n",
    "1. Initialization:\n",
    "    * Start with all data points in a single cluster.\n",
    "\n",
    "2. Split Clusters:\n",
    "    * At each step, split the cluster into the two least similar clusters.\n",
    "\n",
    "3. Repeat:\n",
    "    * Repeat the splitting steps until each data point is in its own cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Divisive.png\" width=\"450\" height=\"350\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Divisive-vs-Agglomerative-Clustering.png\" width=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dendrogram\n",
    "\n",
    "A dendrogram is a tree-like diagram that records the sequences of merges or splits. The height of the branches indicates the distance or dissimilarity between clusters. Cutting the dendrogram at a specific height can provide different numbers of clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"dendogram.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference B/W K means and Hierarchal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certainly! Here's the updated table including the handling of categorical and numerical data:\n",
    "\n",
    "| Feature                     | K-means Clustering                                    | Hierarchical Clustering                               |\n",
    "|-----------------------------|-------------------------------------------------------|------------------------------------------------------|\n",
    "| **Initialization**          | Requires the number of clusters \\( K \\) to be specified beforehand. | Does not require the number of clusters to be specified. |\n",
    "| **Algorithm Type**          | Partition-based                                      | Hierarchical (can be agglomerative or divisive)      |\n",
    "| **Cluster Formation**       | Iteratively updates centroids and assigns points to nearest centroid. | Builds a tree of clusters by successive merging (agglomerative) or splitting (divisive). |\n",
    "| **Distance Metric**         | Typically uses Euclidean distance, but others can be used. | Multiple linkage criteria (single, complete, average, Ward's method) with various distance metrics. |\n",
    "| **Time Complexity**         | Generally \\( O(n \\cdot k \\cdot t) \\), where \\( n \\) is the number of points, \\( k \\) is the number of clusters, and \\( t \\) is the number of iterations. | Generally \\( O(n^3) \\) for agglomerative methods; more computationally intensive than K-means. |\n",
    "| **Scalability**             | Scalable to large datasets.                          | Not as scalable to large datasets due to higher computational complexity. |\n",
    "| **Data Size**               | Suitable for large datasets.                         | More suitable for smaller datasets (typically less than a few thousand data points). |\n",
    "| **Handling of Data Types**  | Primarily suitable for numerical data. Extensions like K-prototypes exist for mixed data types. | Can handle both numerical and categorical data, depending on the distance metric used. |\n",
    "| **Output**                  | Flat partition of clusters.                          | Dendrogram representing nested clusters.             |\n",
    "| **Cluster Shape**           | Assumes spherical clusters of similar size.           | Can capture clusters of arbitrary shape and size.    |\n",
    "| **Stability**               | Sensitive to initial centroid placement; multiple runs with different initializations recommended. | More stable results as it does not depend on initial parameters. |\n",
    "| **Handling of Noise**       | Less robust to noise and outliers.                    | More robust to noise and outliers.                   |\n",
    "| **Hierarchical Structure**  | Does not provide hierarchical relationships between clusters. | Provides a hierarchy of clusters, useful for exploring data at different levels of granularity. |\n",
    "| **Memory Usage**            | Typically lower memory usage.                        | Higher memory usage due to the storage of the distance matrix. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Polynomial regression** is a type of regression analysis where the relationship between the independent variable x \n",
    "and the dependent variable y is modeled as an nth-degree polynomial function. \n",
    "It extends linear regression by allowing the relationship between x and y to be nonlinear.\n",
    "\n",
    "The general form of a polynomial regression equation of degree n is:\n",
    "\n",
    "y = beta_0 + beta_1x + beta_2x^2 + ...... + beta_nx^n \n",
    "\n",
    "Where:\n",
    "-y is the dependent variable.\n",
    "-x is the independent variable.\n",
    "- beta_0, beta_1, beta_2, ....., beta_n are the coefficients of the polynomial terms.\n",
    "\n",
    "Polynomial regression can capture more complex relationships between variables compared to linear regression. It can fit curves to data, allowing for better modeling of nonlinear relationships.\n",
    "\n",
    "However, polynomial regression has some limitations. It can be prone to overfitting, especially with higher-degree polynomials, and extrapolation beyond the range of the observed data can lead to unreliable predictions. Therefore, careful consideration is needed when selecting the degree of the polynomial and evaluating the model's performance. Regularization techniques like ridge regression or Lasso regression can be used to mitigate overfitting in polynomial regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"plynomialvslienar.png\" width=\"480\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Polynomial Regression equation for one independent feature (X1)\n",
    "\n",
    "\n",
    "<img src=\"polynomial-equation.png\" width=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Polynomial Regression equation for multiple independent feature and **degree = 2 (max power can be 2)** (for example X1,X2,X3)\n",
    "\n",
    "    For polynomial regression with three independent features and a polynomial degree of 2, the equation would look like this:\n",
    "\n",
    "y = beta_0 + beta_1 x_1 + beta_2 x_2 + beta_3 x_3 + beta_4 x_1^2 + beta_5 x_2^2 + beta_6 x_3^2 + beta_7 x_1x_2 + beta_8 x_1x_3 + beta_9 x_2x_3 + epsilon \n",
    "\n",
    "Where:\n",
    "- y  is the dependent variable.\n",
    "- x_1, x_2, x_3  are the three independent features.\n",
    "- beta_0, beta_1, beta_2, ....., beta_9  are the coefficients of the polynomial terms.\n",
    "- epsilon represents the error term.\n",
    "\n",
    "This equation includes linear terms for each independent feature x_1, x_2, x_3, quadratic terms for each independent feature x_1^2, x_2^2, x_3^2, and interaction terms x_1x_2, x_1x_3, x_2x_3. \n",
    "\n",
    "It allows the model to capture both linear and quadratic relationships between the independent features and the dependent variable, as well as interactions between the features.\n",
    "\n",
    "\n",
    "**Same Equation for degree 3** would be\n",
    "\n",
    "The general form of a polynomial regression equation with three independent features (洧논1, 洧논2, and 洧논3) can be expressed as follows:\n",
    "\n",
    "洧녽=洧띻0+洧띻1洧논1+洧띻2洧논2+洧띻3洧논3+洧띻4洧논1^2+洧띻5洧논1洧논2+洧띻6洧논1洧논3+洧띻7洧논2^2+洧띻8洧논2洧논3+洧띻9洧논3^2+洧띻10洧논1^3+洧띻11洧논1^2 洧논2+洧띻12洧논1^2 洧논3+洧띻13洧논1 洧논2^2+洧띻14洧논1洧논2洧논3+洧띻15洧논1 洧논3^2+洧띻16洧논2^3+洧띻17洧논2^2 洧논3+洧띻18洧논2 洧논3^2+洧띻19洧논3^3+洧랬\n",
    "\n",
    "<img src=\"ploynomial-degree3.jpg\" width=\"750\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
